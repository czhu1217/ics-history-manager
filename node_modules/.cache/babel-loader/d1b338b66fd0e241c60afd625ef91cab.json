{"ast":null,"code":"import _regeneratorRuntime from \"C:\\\\Users\\\\cindy\\\\Documents\\\\GitHub\\\\todo-list-icon-classification-with-tensorflow-js\\\\node_modules\\\\@babel\\\\runtime/regenerator\";\nimport * as tf from \"@tensorflow/tfjs\";\nimport * as tfvis from \"@tensorflow/tfjs-vis\";\n\nvar learnTodos = require(\"./data/learn_todos.json\");\n\nvar exerciseTodos = require(\"./data/exercise_todos.json\");\n\nvar trainTasks = learnTodos.concat(exerciseTodos);\nvar MODEL_NAME = \"suggestion-model\";\nvar N_CLASSES = 2;\n\nvar encodeData = function encodeData(encoder, tasks) {\n  var sentences, embeddings;\n  return _regeneratorRuntime.async(function encodeData$(_context) {\n    while (1) {\n      switch (_context.prev = _context.next) {\n        case 0:\n          sentences = tasks.map(function (t) {\n            return t.text.toLowerCase();\n          });\n          _context.next = 3;\n          return _regeneratorRuntime.awrap(encoder.embed(sentences));\n\n        case 3:\n          embeddings = _context.sent;\n          return _context.abrupt(\"return\", embeddings);\n\n        case 5:\n        case \"end\":\n          return _context.stop();\n      }\n    }\n  });\n};\n\nvar trainModel = function trainModel(encoder) {\n  var loadedModel, xTrain, yTrain, model, lossContainer;\n  return _regeneratorRuntime.async(function trainModel$(_context2) {\n    while (1) {\n      switch (_context2.prev = _context2.next) {\n        case 0:\n          _context2.prev = 0;\n          _context2.next = 3;\n          return _regeneratorRuntime.awrap(tf.loadLayersModel(\"localstorage://\".concat(MODEL_NAME)));\n\n        case 3:\n          loadedModel = _context2.sent;\n          console.log(\"Using existing model\");\n          return _context2.abrupt(\"return\", loadedModel);\n\n        case 8:\n          _context2.prev = 8;\n          _context2.t0 = _context2[\"catch\"](0);\n          console.log(\"Training new model\");\n\n        case 11:\n          _context2.next = 13;\n          return _regeneratorRuntime.awrap(encodeData(encoder, trainTasks));\n\n        case 13:\n          xTrain = _context2.sent;\n          yTrain = tf.tensor2d(trainTasks.map(function (t) {\n            return [t.icon === \"BOOK\" ? 1 : 0, t.icon === \"RUN\" ? 1 : 0];\n          }));\n          model = tf.sequential();\n          model.add(tf.layers.dense({\n            inputShape: [xTrain.shape[1]],\n            activation: \"softmax\",\n            units: N_CLASSES\n          }));\n          model.compile({\n            loss: \"categoricalCrossentropy\",\n            optimizer: tf.train.adam(0.001),\n            metrics: [\"accuracy\"]\n          });\n          lossContainer = document.getElementById(\"loss-cont\");\n          _context2.next = 21;\n          return _regeneratorRuntime.awrap(model.fit(xTrain, yTrain, {\n            batchSize: 32,\n            validationSplit: 0.1,\n            shuffle: true,\n            epochs: 150,\n            callbacks: tfvis.show.fitCallbacks(lossContainer, [\"loss\", \"val_loss\", \"acc\", \"val_acc\"], {\n              callbacks: [\"onEpochEnd\"]\n            })\n          }));\n\n        case 21:\n          _context2.next = 23;\n          return _regeneratorRuntime.awrap(model.save(\"localstorage://\".concat(MODEL_NAME)));\n\n        case 23:\n          return _context2.abrupt(\"return\", model);\n\n        case 24:\n        case \"end\":\n          return _context2.stop();\n      }\n    }\n  }, null, null, [[0, 8]]);\n};\n\nvar suggestIcon = function suggestIcon(model, encoder, taskName, threshold) {\n  var xPredict, prediction;\n  return _regeneratorRuntime.async(function suggestIcon$(_context3) {\n    while (1) {\n      switch (_context3.prev = _context3.next) {\n        case 0:\n          if (taskName.trim().includes(\" \")) {\n            _context3.next = 2;\n            break;\n          }\n\n          return _context3.abrupt(\"return\", null);\n\n        case 2:\n          _context3.next = 4;\n          return _regeneratorRuntime.awrap(encodeData(encoder, [{\n            text: taskName\n          }]));\n\n        case 4:\n          xPredict = _context3.sent;\n          _context3.next = 7;\n          return _regeneratorRuntime.awrap(model.predict(xPredict).data());\n\n        case 7:\n          prediction = _context3.sent;\n\n          if (!(prediction[0] > threshold)) {\n            _context3.next = 12;\n            break;\n          }\n\n          return _context3.abrupt(\"return\", \"BOOK\");\n\n        case 12:\n          if (!(prediction[1] > threshold)) {\n            _context3.next = 16;\n            break;\n          }\n\n          return _context3.abrupt(\"return\", \"RUN\");\n\n        case 16:\n          return _context3.abrupt(\"return\", null);\n\n        case 17:\n        case \"end\":\n          return _context3.stop();\n      }\n    }\n  });\n};\n\nexport { suggestIcon, trainModel };","map":{"version":3,"sources":["C:/Users/cindy/Documents/GitHub/todo-list-icon-classification-with-tensorflow-js/src/suggestions/model.js"],"names":["tf","tfvis","learnTodos","require","exerciseTodos","trainTasks","concat","MODEL_NAME","N_CLASSES","encodeData","encoder","tasks","sentences","map","t","text","toLowerCase","embed","embeddings","trainModel","loadLayersModel","loadedModel","console","log","xTrain","yTrain","tensor2d","icon","model","sequential","add","layers","dense","inputShape","shape","activation","units","compile","loss","optimizer","train","adam","metrics","lossContainer","document","getElementById","fit","batchSize","validationSplit","shuffle","epochs","callbacks","show","fitCallbacks","save","suggestIcon","taskName","threshold","trim","includes","xPredict","predict","data","prediction"],"mappings":";AAAA,OAAO,KAAKA,EAAZ,MAAoB,kBAApB;AACA,OAAO,KAAKC,KAAZ,MAAuB,sBAAvB;;AACA,IAAMC,UAAU,GAAGC,OAAO,CAAC,yBAAD,CAA1B;;AACA,IAAMC,aAAa,GAAGD,OAAO,CAAC,4BAAD,CAA7B;;AAEA,IAAME,UAAU,GAAGH,UAAU,CAACI,MAAX,CAAkBF,aAAlB,CAAnB;AAEA,IAAMG,UAAU,GAAG,kBAAnB;AACA,IAAMC,SAAS,GAAG,CAAlB;;AAEA,IAAMC,UAAU,GAAG,SAAbA,UAAa,CAAOC,OAAP,EAAgBC,KAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AACXC,UAAAA,SADW,GACCD,KAAK,CAACE,GAAN,CAAU,UAAAC,CAAC;AAAA,mBAAIA,CAAC,CAACC,IAAF,CAAOC,WAAP,EAAJ;AAAA,WAAX,CADD;AAAA;AAAA,2CAEQN,OAAO,CAACO,KAAR,CAAcL,SAAd,CAFR;;AAAA;AAEXM,UAAAA,UAFW;AAAA,2CAGVA,UAHU;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,CAAnB;;AAMA,IAAMC,UAAU,GAAG,SAAbA,UAAa,CAAMT,OAAN;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,2CAEWV,EAAE,CAACoB,eAAH,0BACNb,UADM,EAFX;;AAAA;AAETc,UAAAA,WAFS;AAKfC,UAAAA,OAAO,CAACC,GAAR,CAAY,sBAAZ;AALe,4CAMRF,WANQ;;AAAA;AAAA;AAAA;AAQfC,UAAAA,OAAO,CAACC,GAAR,CAAY,oBAAZ;;AARe;AAAA;AAAA,2CAWId,UAAU,CAACC,OAAD,EAAUL,UAAV,CAXd;;AAAA;AAWXmB,UAAAA,MAXW;AAaXC,UAAAA,MAbW,GAaFzB,EAAE,CAAC0B,QAAH,CACbrB,UAAU,CAACQ,GAAX,CAAe,UAAAC,CAAC;AAAA,mBAAI,CAACA,CAAC,CAACa,IAAF,KAAW,MAAX,GAAoB,CAApB,GAAwB,CAAzB,EAA4Bb,CAAC,CAACa,IAAF,KAAW,KAAX,GAAmB,CAAnB,GAAuB,CAAnD,CAAJ;AAAA,WAAhB,CADa,CAbE;AAiBXC,UAAAA,KAjBW,GAiBH5B,EAAE,CAAC6B,UAAH,EAjBG;AAmBjBD,UAAAA,KAAK,CAACE,GAAN,CACE9B,EAAE,CAAC+B,MAAH,CAAUC,KAAV,CAAgB;AACdC,YAAAA,UAAU,EAAE,CAACT,MAAM,CAACU,KAAP,CAAa,CAAb,CAAD,CADE;AAEdC,YAAAA,UAAU,EAAE,SAFE;AAGdC,YAAAA,KAAK,EAAE5B;AAHO,WAAhB,CADF;AAQAoB,UAAAA,KAAK,CAACS,OAAN,CAAc;AACZC,YAAAA,IAAI,EAAE,yBADM;AAEZC,YAAAA,SAAS,EAAEvC,EAAE,CAACwC,KAAH,CAASC,IAAT,CAAc,KAAd,CAFC;AAGZC,YAAAA,OAAO,EAAE,CAAC,UAAD;AAHG,WAAd;AAMMC,UAAAA,aAjCW,GAiCKC,QAAQ,CAACC,cAAT,CAAwB,WAAxB,CAjCL;AAAA;AAAA,2CAmCXjB,KAAK,CAACkB,GAAN,CAAUtB,MAAV,EAAkBC,MAAlB,EAA0B;AAC9BsB,YAAAA,SAAS,EAAE,EADmB;AAE9BC,YAAAA,eAAe,EAAE,GAFa;AAG9BC,YAAAA,OAAO,EAAE,IAHqB;AAI9BC,YAAAA,MAAM,EAAE,GAJsB;AAK9BC,YAAAA,SAAS,EAAElD,KAAK,CAACmD,IAAN,CAAWC,YAAX,CACTV,aADS,EAET,CAAC,MAAD,EAAS,UAAT,EAAqB,KAArB,EAA4B,SAA5B,CAFS,EAGT;AACEQ,cAAAA,SAAS,EAAE,CAAC,YAAD;AADb,aAHS;AALmB,WAA1B,CAnCW;;AAAA;AAAA;AAAA,2CAiDXvB,KAAK,CAAC0B,IAAN,0BAA6B/C,UAA7B,EAjDW;;AAAA;AAAA,4CAmDVqB,KAnDU;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,CAAnB;;AAsDA,IAAM2B,WAAW,GAAG,SAAdA,WAAc,CAAO3B,KAAP,EAAclB,OAAd,EAAuB8C,QAAvB,EAAiCC,SAAjC;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cACbD,QAAQ,CAACE,IAAT,GAAgBC,QAAhB,CAAyB,GAAzB,CADa;AAAA;AAAA;AAAA;;AAAA,4CAET,IAFS;;AAAA;AAAA;AAAA,2CAIKlD,UAAU,CAACC,OAAD,EAAU,CAAC;AAAEK,YAAAA,IAAI,EAAEyC;AAAR,WAAD,CAAV,CAJf;;AAAA;AAIZI,UAAAA,QAJY;AAAA;AAAA,2CAMOhC,KAAK,CAACiC,OAAN,CAAcD,QAAd,EAAwBE,IAAxB,EANP;;AAAA;AAMZC,UAAAA,UANY;;AAAA,gBAQdA,UAAU,CAAC,CAAD,CAAV,GAAgBN,SARF;AAAA;AAAA;AAAA;;AAAA,4CAST,MATS;;AAAA;AAAA,gBAUPM,UAAU,CAAC,CAAD,CAAV,GAAgBN,SAVT;AAAA;AAAA;AAAA;;AAAA,4CAWT,KAXS;;AAAA;AAAA,4CAaT,IAbS;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,CAApB;;AAiBA,SAASF,WAAT,EAAsBpC,UAAtB","sourcesContent":["import * as tf from \"@tensorflow/tfjs\";\r\nimport * as tfvis from \"@tensorflow/tfjs-vis\";\r\nconst learnTodos = require(\"./data/learn_todos.json\");\r\nconst exerciseTodos = require(\"./data/exercise_todos.json\");\r\n\r\nconst trainTasks = learnTodos.concat(exerciseTodos);\r\n\r\nconst MODEL_NAME = \"suggestion-model\";\r\nconst N_CLASSES = 2;\r\n\r\nconst encodeData = async (encoder, tasks) => {\r\n  const sentences = tasks.map(t => t.text.toLowerCase());\r\n  const embeddings = await encoder.embed(sentences);\r\n  return embeddings;\r\n};\r\n\r\nconst trainModel = async encoder => {\r\n  try {\r\n    const loadedModel = await tf.loadLayersModel(\r\n      `localstorage://${MODEL_NAME}`\r\n    );\r\n    console.log(\"Using existing model\");\r\n    return loadedModel;\r\n  } catch (e) {\r\n    console.log(\"Training new model\");\r\n  }\r\n\r\n  const xTrain = await encodeData(encoder, trainTasks);\r\n\r\n  const yTrain = tf.tensor2d(\r\n    trainTasks.map(t => [t.icon === \"BOOK\" ? 1 : 0, t.icon === \"RUN\" ? 1 : 0])\r\n  );\r\n\r\n  const model = tf.sequential();\r\n\r\n  model.add(\r\n    tf.layers.dense({\r\n      inputShape: [xTrain.shape[1]],\r\n      activation: \"softmax\",\r\n      units: N_CLASSES\r\n    })\r\n  );\r\n\r\n  model.compile({\r\n    loss: \"categoricalCrossentropy\",\r\n    optimizer: tf.train.adam(0.001),\r\n    metrics: [\"accuracy\"]\r\n  });\r\n\r\n  const lossContainer = document.getElementById(\"loss-cont\");\r\n\r\n  await model.fit(xTrain, yTrain, {\r\n    batchSize: 32,\r\n    validationSplit: 0.1,\r\n    shuffle: true,\r\n    epochs: 150,\r\n    callbacks: tfvis.show.fitCallbacks(\r\n      lossContainer,\r\n      [\"loss\", \"val_loss\", \"acc\", \"val_acc\"],\r\n      {\r\n        callbacks: [\"onEpochEnd\"]\r\n      }\r\n    )\r\n  });\r\n\r\n  await model.save(`localstorage://${MODEL_NAME}`);\r\n\r\n  return model;\r\n};\r\n\r\nconst suggestIcon = async (model, encoder, taskName, threshold) => {\r\n  if (!taskName.trim().includes(\" \")) {\r\n    return null;\r\n  }\r\n  const xPredict = await encodeData(encoder, [{ text: taskName }]);\r\n\r\n  const prediction = await model.predict(xPredict).data();\r\n\r\n  if (prediction[0] > threshold) {\r\n    return \"BOOK\";\r\n  } else if (prediction[1] > threshold) {\r\n    return \"RUN\";\r\n  } else {\r\n    return null;\r\n  }\r\n};\r\n\r\nexport { suggestIcon, trainModel };\r\n"]},"metadata":{},"sourceType":"module"}